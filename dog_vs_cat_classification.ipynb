{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog-vs-cat-classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvPKYSV4RV1P"
      },
      "source": [
        "#This should perform every time when we run\n",
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_CPV0AjRft-"
      },
      "source": [
        "#This should perform every time when we run\n",
        "!unzip kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5CJGe5VVFIz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import os\n",
        "from keras.preprocessing.image import load_img\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs-1LWEwRyDL",
        "outputId": "df96eaca-cdf1-4e10-a5b0-71a9dd616015"
      },
      "source": [
        "input_path=[]\n",
        "label=[]\n",
        "dir='PetImages'\n",
        "for class_path in os.listdir(dir):\n",
        "  for path in os.listdir(dir+'/'+class_path):\n",
        "    if class_path == 'Cat':\n",
        "      label.append(0)\n",
        "    else:\n",
        "      label.append(1)\n",
        "    input_path.append(os.path.join('PetImages',class_path,path))\n",
        "print(input_path[11456])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PetImages/Dog/7447.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mPZX2j_WkF1"
      },
      "source": [
        "data=pd.DataFrame({\"image_path\":input_path,\"category\":label})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "VnxW4hKFW_EX",
        "outputId": "7ac9106b-0ca3-4bff-891e-7dfb68105570"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PetImages/Dog/10766.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PetImages/Dog/8035.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PetImages/Dog/8245.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PetImages/Dog/955.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PetImages/Dog/7310.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_path  category\n",
              "0  PetImages/Dog/10766.jpg         1\n",
              "1   PetImages/Dog/8035.jpg         1\n",
              "2   PetImages/Dog/8245.jpg         1\n",
              "3    PetImages/Dog/955.jpg         1\n",
              "4   PetImages/Dog/7310.jpg         1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQwvJh7IXfen"
      },
      "source": [
        "Shuffle the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkSmMlWpXIMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7a6375cc-a874-4d69-bd32-2afd4093eb8f"
      },
      "source": [
        "data=data.sample(frac=1).reset_index(drop=True)\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PetImages/Dog/8801.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PetImages/Cat/4049.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PetImages/Dog/7253.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PetImages/Cat/11268.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PetImages/Dog/7038.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_path  category\n",
              "0   PetImages/Dog/8801.jpg         1\n",
              "1   PetImages/Cat/4049.jpg         0\n",
              "2   PetImages/Dog/7253.jpg         1\n",
              "3  PetImages/Cat/11268.jpg         0\n",
              "4   PetImages/Dog/7038.jpg         1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inD73klnDaEW",
        "outputId": "0301bc17-1055-4fca-bd9e-c1a967c9f191"
      },
      "source": [
        "for i in data['image_path']:\n",
        "  if '.jpg' not in i:\n",
        "    print(i)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PetImages/Dog/Thumbs.db\n",
            "PetImages/Cat/Thumbs.db\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipD06LZSEsRU",
        "outputId": "6c827961-1a96-46b6-8963-89b68343b446"
      },
      "source": [
        "#delete the files\n",
        "data= data[data['image_path']!='PetImages/Dog/Thumbs.db']\n",
        "print(len(data))\n",
        "data= data[data['image_path']!='PetImages/Cat/Thumbs.db']\n",
        "len(data)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5w2Kn9SGVpW",
        "outputId": "a66c1865-fe2a-4908-a1ee-5354c69f3358"
      },
      "source": [
        "import PIL\n",
        "l=[]\n",
        "for image in data['image_path']:\n",
        "  try:\n",
        "    img=PIL.Image.open(image)\n",
        "  except:\n",
        "    l.append(image)\n",
        "l"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PetImages/Dog/11702.jpg', 'PetImages/Cat/666.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN6UmXLDHA4z"
      },
      "source": [
        "data= data[data['image_path']!='PetImages/Dog/11702.jpg']\n",
        "data= data[data['image_path']!='PetImages/Cat/666.jpg']"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4CszvL7ZRpF"
      },
      "source": [
        "## Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLMiUchrXvWj"
      },
      "source": [
        "import random\n",
        "plt.figure(figsize=(25,25))\n",
        "temp=data[data['category']==0]['image_path']\n",
        "start=random.randint(0,len(temp))\n",
        "files=temp[start:start+25]\n",
        "for index,x in enumerate(files):\n",
        "  plt.subplot(5,5,index+1)\n",
        "  img=load_img(x)\n",
        "  img=np.array(img)\n",
        "  plt.imshow(img)\n",
        "  plt.title('Cats')\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DUpaghXkachh",
        "outputId": "f49e70f1-0250-46db-b157-97ece04e386e"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "temp=data[data['category']==1]['image_path']\n",
        "start=random.randint(0,len(temp))\n",
        "files=temp[start:start+12]\n",
        "for index,file in enumerate(files):\n",
        "  plt.subplot(3,4,index+1)\n",
        "  img=load_img(file)\n",
        "  img=np.array(img)\n",
        "  plt.imshow(img)\n",
        "  plt.title('Dogs')\n",
        "  plt.axis('off')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN7VMAW1bLj4"
      },
      "source": [
        "#Checking for blanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "QbkkmN3Qa3qm",
        "outputId": "fb3fdf39-b57f-4051-e7c5-c6c374f205e0"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(data['category'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9be8517f10>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsri3MtUbaeA"
      },
      "source": [
        "data['category']=data['category'].astype('str')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzT3R7ludRV0",
        "outputId": "8ca8d114-efe3-4936-c64c-c5e98e35e74d"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "image_path    object\n",
              "category      object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUtotOI8e6EA"
      },
      "source": [
        "#Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO99KRRydUIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "3e8717d2-d393-4538-e502-d4a7a25f92b2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data=train_test_split(data,test_size=0.2,random_state=43)\n",
        "#split train_data into validattion and train data\n",
        "train_df,val_data=train_test_split(train_data,test_size=0.2,random_state=43)\n",
        "test_data.head()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11151</th>\n",
              "      <td>PetImages/Cat/6537.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8044</th>\n",
              "      <td>PetImages/Dog/209.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2831</th>\n",
              "      <td>PetImages/Cat/1116.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4608</th>\n",
              "      <td>PetImages/Cat/3055.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3494</th>\n",
              "      <td>PetImages/Dog/5766.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   image_path category\n",
              "11151  PetImages/Cat/6537.jpg        0\n",
              "8044    PetImages/Dog/209.jpg        1\n",
              "2831   PetImages/Cat/1116.jpg        0\n",
              "4608   PetImages/Cat/3055.jpg        0\n",
              "3494   PetImages/Dog/5766.jpg        1"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y01-lzBvfi5m"
      },
      "source": [
        "#Image_data_generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv-GwpKwezGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdfcac6-e17b-43f6-a2f1-98839b51dd81"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=57,\n",
        "    shear_range=0.4,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_iterator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='category',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "val_iterator = val_datagen.flow_from_dataframe(\n",
        "        val_data,\n",
        "        x_col='image_path',\n",
        "        y_col='category',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15998 validated image filenames belonging to 2 classes.\n",
            "Found 4000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV0LYIgx_FRL"
      },
      "source": [
        "#Model_building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5sJVKxD9BYt"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "model=Sequential([\n",
        "                  #first cnn layer\n",
        "                  Conv2D(32,(3,3),activation='relu', kernel_initializer='he_uniform', input_shape=(150,150,3)),\n",
        "                  MaxPool2D((2,2)),\n",
        "                  #second cnn layer\n",
        "                  Conv2D(20, (3,3), activation='relu', kernel_initializer='he_uniform'),\n",
        "                  MaxPool2D((2,2)),\n",
        "                  #third cnn layer\n",
        "                  Conv2D(15, (3,3), activation='relu', kernel_initializer='he_uniform'),\n",
        "                  MaxPool2D((2,2)),\n",
        "                  #flatten layer\n",
        "                  Flatten(),\n",
        "                  #First Dense layer\n",
        "                  Dense(units=64, activation=\"relu\", kernel_initializer='he_uniform'),\n",
        "                  #Second Dense layer\n",
        "                  Dense(units=35, activation=\"relu\", kernel_initializer='he_uniform'),\n",
        "                  #output layer..\n",
        "                  Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0BT3x_dBTzV",
        "outputId": "d1a9f11e-1ef9-4929-ef77-ed6ef6450327"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 72, 72, 20)        5780      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 36, 36, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 34, 34, 15)        2715      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 17, 17, 15)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 4335)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                277504    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 35)                2275      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 36        \n",
            "=================================================================\n",
            "Total params: 289,206\n",
            "Trainable params: 289,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69qEFxgQBoFd",
        "outputId": "24cab542-c3e6-4669-a593-ac9491e18186"
      },
      "source": [
        "cnn=model.fit_generator(train_iterator, epochs=10, validation_data=val_iterator)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "500/500 [==============================] - 148s 297ms/step - loss: 0.4745 - accuracy: 0.7729 - val_loss: 0.5217 - val_accuracy: 0.7308\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 145s 290ms/step - loss: 0.4727 - accuracy: 0.7745 - val_loss: 0.4523 - val_accuracy: 0.7820\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 146s 292ms/step - loss: 0.4644 - accuracy: 0.7776 - val_loss: 0.4446 - val_accuracy: 0.7872\n",
            "Epoch 4/10\n",
            "500/500 [==============================] - 146s 292ms/step - loss: 0.4637 - accuracy: 0.7772 - val_loss: 0.4941 - val_accuracy: 0.7495\n",
            "Epoch 5/10\n",
            "500/500 [==============================] - 147s 294ms/step - loss: 0.4590 - accuracy: 0.7828 - val_loss: 0.4492 - val_accuracy: 0.7847\n",
            "Epoch 6/10\n",
            "500/500 [==============================] - 148s 295ms/step - loss: 0.4528 - accuracy: 0.7887 - val_loss: 0.4311 - val_accuracy: 0.8025\n",
            "Epoch 7/10\n",
            "500/500 [==============================] - 148s 296ms/step - loss: 0.4477 - accuracy: 0.7857 - val_loss: 0.4297 - val_accuracy: 0.7980\n",
            "Epoch 8/10\n",
            "500/500 [==============================] - 147s 294ms/step - loss: 0.4463 - accuracy: 0.7941 - val_loss: 0.4378 - val_accuracy: 0.8015\n",
            "Epoch 9/10\n",
            "500/500 [==============================] - 147s 294ms/step - loss: 0.4424 - accuracy: 0.7927 - val_loss: 0.4179 - val_accuracy: 0.8087\n",
            "Epoch 10/10\n",
            "500/500 [==============================] - 148s 296ms/step - loss: 0.4403 - accuracy: 0.7933 - val_loss: 0.4512 - val_accuracy: 0.7870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSPshF6IcbCB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}